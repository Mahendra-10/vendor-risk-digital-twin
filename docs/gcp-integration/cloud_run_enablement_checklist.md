# Cloud Run Integration Enablement Checklist

**Before enabling Cloud Run integration, verify these items:**

---

## ‚úÖ **What Will Work (Already Verified)**

### 1. Service is Deployed and Healthy ‚úÖ
- **Status:** Service is running at `https://simulation-service-16418516910.us-central1.run.app`
- **Health Check:** `{"status":"healthy","neo4j":"connected"}`
- **Last Deployed:** 2025-11-28 22:58:41

### 2. Service Responds Correctly ‚úÖ
- **Test Result:** Successfully returns simulation results
- **Response Format:** Valid JSON with all expected fields:
  - `vendor`, `duration_hours`, `operational_impact`, `financial_impact`
  - `compliance_impact`, `overall_impact_score`, `recommendations`
  - `simulation_id`, `timestamp`, `service`

### 3. CORS is Enabled ‚úÖ
- **Code:** `CORS(app)` in `app.py` line 45
- **Status:** Allows cross-origin requests from dashboard

### 4. Neo4j Connection Works ‚úÖ
- **Status:** Logs show "Loaded Neo4j credentials from GCP Secret Manager"
- **Health Check:** Confirms `"neo4j":"connected"`

### 5. API Endpoint Works ‚úÖ
- **Test:** `POST /simulate` with `{"vendor": "stripe", "duration": 4}`
- **Result:** Returns complete simulation data
- **Status Code:** 200 OK

---

## ‚ö†Ô∏è **Potential Issues to Watch For**

### 1. Vendor Name Normalization (Medium Risk)

**Issue:** Dashboard sends lowercase vendor names, but validation might fail.

**What Happens:**
- Dashboard gets vendors: `["Stripe", "Auth0"]` (display names)
- User selects: `"Stripe"`
- Dashboard normalizes: `"stripe"` (lowercase)
- Sends to Cloud Run: `{vendor: "stripe"}`
- Cloud Run queries Neo4j: `{name: "stripe"}` ‚úÖ (should work)

**Risk Level:** Medium
- **Why:** Neo4j stores vendors with `name` (lowercase) and `display_name` (proper case)
- **Mitigation:** Code already normalizes correctly (line 216 in `server.js`)

**Test After Enablement:**
```bash
# Test with different vendor names
curl -X POST https://simulation-service-16418516910.us-central1.run.app/simulate \
  -H "Content-Type: application/json" \
  -d '{"vendor": "stripe", "duration": 4}'
```

---

### 2. Response Structure Differences (Low Risk)

**Issue:** Response format might differ slightly between local and Cloud Run.

**What to Check:**
- **Local Simulator:** Returns `simulation_timestamp`
- **Cloud Run:** Returns `timestamp` (different field name)
- **Dashboard Code:** Handles both (line 247-249)

**Risk Level:** Low
- **Why:** Dashboard already handles missing `simulation_timestamp` (adds it if missing)
- **Mitigation:** Code already handles this gracefully

**Fields to Verify:**
- ‚úÖ `compliance_impact` structure
- ‚úÖ `operational_impact` structure  
- ‚úÖ `financial_impact` structure
- ‚úÖ `overall_impact_score` calculation

---

### 3. Error Handling (Low Risk)

**Issue:** Errors might be silently caught and fall back to local.

**Current Behavior:**
```javascript
catch (cloudError) {
  logger.warn(`Cloud Run simulation failed: ${cloudError.message}, falling back to local`);
  // Falls through to local simulation
}
```

**Risk Level:** Low
- **Why:** Has fallback to local simulator
- **Mitigation:** Errors are logged, but user might not see them

**What to Monitor:**
- Check dashboard server logs for warnings
- Watch for fallback messages
- Verify Cloud Run logs if issues occur

---

### 4. Network/Timeout Issues (Low Risk)

**Issue:** Network latency or timeouts between dashboard and Cloud Run.

**Risk Level:** Low
- **Why:** Cloud Run is in same region (us-central1)
- **Mitigation:** Cloud Run has auto-scaling and should respond quickly

**What to Watch:**
- Response times
- Timeout errors
- Connection errors

---

## üìã **Pre-Enablement Checklist**

Before making changes, verify:

- [x] Cloud Run service is deployed ‚úÖ
- [x] Service health check passes ‚úÖ
- [x] Service responds to API calls ‚úÖ
- [x] CORS is enabled ‚úÖ
- [x] Neo4j connection works ‚úÖ
- [ ] **Dashboard has vendor data loaded** (check Neo4j)
- [ ] **Environment variable option** (can use `SIMULATION_SERVICE_URL` env var instead of hardcoding)

---

## üîß **Changes Required**

### Change 1: Update URL (Line 25)
```javascript
// OLD (wrong):
const SIMULATION_SERVICE_URL = process.env.SIMULATION_SERVICE_URL || 
  'https://simulation-service-wearla5naa-uc.a.run.app';

// NEW (correct):
const SIMULATION_SERVICE_URL = process.env.SIMULATION_SERVICE_URL || 
  'https://simulation-service-16418516910.us-central1.run.app';
```

### Change 2: Re-enable Integration (Line 212)
```javascript
// OLD (disabled):
if (false && useCloud && SIMULATION_SERVICE_URL) {

// NEW (enabled):
if (useCloud && SIMULATION_SERVICE_URL) {
```

---

## ‚úÖ **What Will Happen After Changes**

### Flow:
1. User clicks "Run Simulation" in dashboard
2. Dashboard sends request to Cloud Run service
3. Cloud Run service:
   - Queries Neo4j for vendor dependencies
   - Calculates operational, financial, compliance impact
   - Publishes result to Pub/Sub (for BigQuery auto-save)
   - Returns result to dashboard
4. Dashboard displays results
5. **Bonus:** Results automatically saved to BigQuery via Pub/Sub

### Benefits:
- ‚úÖ Automatic BigQuery saving (no manual step)
- ‚úÖ Consistent results (same Python simulator)
- ‚úÖ Better error handling (Cloud Run logs)
- ‚úÖ Scalable (Cloud Run auto-scales)

---

## üß™ **Testing After Enablement**

### Test 1: Basic Simulation
1. Open dashboard
2. Select a vendor (e.g., "Stripe")
3. Set duration (e.g., 4 hours)
4. Click "Run Simulation"
5. **Expected:** Results appear, no errors
6. **Check:** Results should show `service: "simulation-service"` (not local)

### Test 2: Check BigQuery (Optional)
```bash
# Verify results were saved to BigQuery
bq query --use_legacy_sql=false \
  'SELECT * FROM `vendor-risk-digital-twin.vendor_risk.simulations` 
   ORDER BY created_at DESC LIMIT 1'
```

### Test 3: Check Logs
```bash
# Dashboard logs (should show Cloud Run call)
# Look for: "Running simulation via Cloud Run"

# Cloud Run logs
gcloud run services logs read simulation-service \
  --region=us-central1 \
  --project=vendor-risk-digital-twin \
  --limit=10
```

---

## ‚ö†Ô∏è **If Something Goes Wrong**

### Fallback Behavior:
- If Cloud Run fails, dashboard automatically falls back to local simulator
- User will see warning: "Simulation ran locally. Results NOT automatically saved to BigQuery"
- Check logs for error details

### Debug Steps:
1. **Check Cloud Run logs:**
   ```bash
   gcloud run services logs read simulation-service --region=us-central1 --limit=50
   ```

2. **Test service directly:**
   ```bash
   curl -X POST https://simulation-service-16418516910.us-central1.run.app/simulate \
     -H "Content-Type: application/json" \
     -d '{"vendor": "stripe", "duration": 4}'
   ```

3. **Check dashboard logs:**
   - Look for "Cloud Run simulation failed" warnings
   - Check for connection errors

4. **Verify Neo4j has data:**
   ```cypher
   MATCH (v:Vendor) RETURN v.name, v.display_name LIMIT 10
   ```

---

## üìä **Success Criteria**

After enabling, you should see:

1. ‚úÖ Simulations run via Cloud Run (check response for `service: "simulation-service"`)
2. ‚úÖ No errors in dashboard console
3. ‚úÖ Results appear correctly formatted
4. ‚úÖ BigQuery auto-saves (check Pub/Sub ‚Üí BigQuery flow)
5. ‚úÖ Cloud Run logs show successful requests

---

## üéØ **Answer: Will This Make Cloud Run Work?**

### **YES, with high confidence!**

**Why:**
1. ‚úÖ Service is deployed and working (verified)
2. ‚úÖ API responds correctly (tested)
3. ‚úÖ CORS is enabled (code confirmed)
4. ‚úÖ Neo4j connection works (health check confirms)
5. ‚úÖ Response format matches expectations (tested)
6. ‚úÖ Error handling has fallback (safe)

**Only Potential Issues:**
- Vendor name normalization (but code already handles this)
- Response structure differences (but dashboard handles this)
- Network issues (unlikely, same region)

**Recommendation:**
- **Go ahead and make the changes**
- **Test with one simulation first**
- **Monitor logs for any issues**
- **If issues occur, fallback to local will work automatically**

---

## üîó **Related Files**

- `dashboard/server.js` - Lines 24-25 (URL), Line 212 (enable/disable)
- `cloud_run/simulation-service/app.py` - Cloud Run service code
- `docs/cloud_run_dashboard_issue_analysis.md` - Detailed issue analysis
